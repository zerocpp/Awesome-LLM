# 大模型幻觉（LLM Hallucination）
- [TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space](notes/TruthX.md) (Zhang et al., 中科院计算所, ACL 2024)

# 大模型水印（LLM Watermarking）
- [Scalable watermarking for identifying large language model outputs](notes/synthid-text.md) (Dathathri et al., DeepMind, Nature 2024)

# 大模型对齐（LLM Alignment）
- [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](notes/DPO.md)(Rafailov et al., Stanford University, NeurIPS 2023 oral)

# 模型编辑（Model Editing）
- [The Butterfly Effect of Model Editing_ Few Edits Can Trigger Large Language Models Collapse](notes/The%20Butterfly%20Effect%20of%20Model%20Editing_%20Few%20Edits%20Can%20Trigger%20Large%20Language%20Models%20Collapse.md)(杨万里 et al., 中科院计算所, ACL 2024 Findings)
