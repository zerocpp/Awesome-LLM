# 大模型幻觉（LLM Hallucination）
- [TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space](notes/TruthX.md) (Zhang et al., 中科院计算所, ACL 2024)
# 大模型水印（LLM Watermarking）
- [Scalable watermarking for identifying large language model outputs](notes/synthid-text.md) (Dathathri et al., DeepMind, Nature 2024)
