(Chen et al., 阿里云, ICLR 2024)

# Abstract
这篇论文提出了一种名为INSIDE的框架，利用大型语言模型（LLM）的内部状态来检测知识幻觉。该框架通过EigenScore指标衡量句子嵌入空间中的语义一致性，并采用测试时特征裁剪方法减少过度自信的生成，从而提高幻觉检测的准确性。实验结果表明，该方法在多个问答数据集上取得了最先进的性能，并在不同模型和超参数设置下展现了鲁棒性。

EigenScore：模型针对同一个问题生成多个回复，然后利用这些回复的嵌入向量计算EigenScore。EigenScore的值反映了不同句子嵌入向量之间的语义差异（熵）。当LLM对答案有信心且生成的多个句子语义相似时，EigenScore值较低；反之，当LLM不确定答案并产生幻觉时，生成的句子语义差异较大，特征值较大，EigenScore值较高。

