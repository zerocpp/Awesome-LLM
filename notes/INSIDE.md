(Chen et al., 阿里云, ICLR 2024)

# Abstract
这篇论文提出了一种名为INSIDE的框架，利用大型语言模型（LLM）的内部状态来检测知识幻觉。该框架通过EigenScore指标衡量句子嵌入空间中的语义一致性，并采用测试时特征裁剪方法减少过度自信的生成，从而提高幻觉检测的准确性。实验结果表明，该方法在多个问答数据集上取得了最先进的性能，并在不同模型和超参数设置下展现了鲁棒性。

# Figures&Tables
![](../attachments/Pasted%20image%2020241119162653.png)

# Note
EigenScore：EigenScore 通过分析 LLM 内部状态中句子嵌入向量的协方差矩阵的特征值来衡量生成文本的语义一致性，从而检测幻觉。
模型针对同一个问题生成多个回复，然后利用这些回复的嵌入向量计算EigenScore。EigenScore的值反映了**不同句子嵌入向量之间的语义差异（熵）**。当LLM对答案有信心且生成的多个句子语义相似时，EigenScore值较低；反之，当LLM不确定答案并产生幻觉时，生成的句子语义差异较大，特征值较大，EigenScore值较高。
**详细计算过程**：
- 获取句子嵌入向量：模型针对同一个问题生成多个回复（句子），对于每个生成的句子，从LLM中间层获取最后一个token的嵌入向量作为该句子的嵌入向量；
- 计算协方差矩阵并正则化；
- 通过奇异值分解计算特征值；
- 计算EigenScore=所有特征值对数的平均值。
